{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1EelphG73c/e0tv7cMfkn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sebastianbarros1976/Neumonia_Xray_AI_Detector/blob/main/Neumonia_AI_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1_Zy_QrLqAu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# COVID-19 Detection Using Chest X-Rays\n",
        "\n",
        "This notebook demonstrates the process of building and deploying a deep learning model for detecting COVID-19 from chest X-ray images. The model will be trained to classify images into three categories: Normal, Viral Pneumonia, and COVID.\n",
        "\n",
        "## Step 1: Setup\n",
        "\n",
        "### Mount Google Drive\n",
        "First, we need to mount Google Drive to access our data and save our model.\n"
      ],
      "metadata": {
        "id": "rqIhggH7LuG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "nPbcwk8NLyk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Required Libraries\n",
        "We need to install specific versions of libraries to ensure compatibility.\n"
      ],
      "metadata": {
        "id": "65I1QM39LzSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall typer -y\n",
        "!pip install typer==0.9.0\n",
        "!pip install gradio -q\n",
        "!pip list | grep \"spacy\\|weasel\\|typer\"\n",
        "!pip install \"typer<0.10.0,>=0.3.0\" --force-reinstall\n",
        "!pip install \"spacy==3.7.4\" --force-reinstall\n",
        "!pip install \"weasel==0.3.4\" --force-reinstall\n",
        "!pip install gradio --force-reinstall\n",
        "!pip list | grep \"spacy\\|weasel\\|typer\"\n",
        "!pip show spacy weasel typer\n",
        "!pip install typer==0.9.0\n"
      ],
      "metadata": {
        "id": "DmjxXbNoL1S4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries\n",
        "Next, we import the necessary libraries for data processing, model building, and deployment."
      ],
      "metadata": {
        "id": "-JUkwohTMI79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import display\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import cv2\n",
        "from PIL import ImageFilter\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from sklearn.metrics import recall_score, confusion_matrix\n",
        "import joblib\n",
        "import gradio as gr\n",
        "import random as python_random\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n"
      ],
      "metadata": {
        "id": "iRF4v3nlMImD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Data Preparation\n",
        "Unzip the Data\n",
        "Unzip the dataset stored in Google Drive."
      ],
      "metadata": {
        "id": "YnAX2WP5MUMo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/MyDrive/Colab Notebooks/X-ray+Data.zip'\n"
      ],
      "metadata": {
        "id": "uIc7_a8lMO79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Data\n",
        "Define functions to generate training and testing data."
      ],
      "metadata": {
        "id": "KAN6YcvRMaQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "height, width = 224, 224\n",
        "batch_size = 64\n",
        "\n",
        "def generate_data(DIR):\n",
        "    datagen = ImageDataGenerator(rescale=1./255.)\n",
        "    generator = datagen.flow_from_directory(\n",
        "        DIR,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        seed=42,\n",
        "        class_mode='sparse',\n",
        "        target_size=(height, width),\n",
        "        classes={'Normal': 0, 'Viral Pneumonia': 1, 'Covid': 2}\n",
        "    )\n",
        "    return generator\n",
        "\n",
        "TRAINING_DIR = '/content/Data/train'\n",
        "TESTING_DIR = '/content/Data/test'\n",
        "\n",
        "train_data = generate_data(TRAINING_DIR)\n",
        "test_data = generate_data(TESTING_DIR)\n",
        "\n",
        "total_image = np.concatenate([train_data.labels, test_data.labels])\n"
      ],
      "metadata": {
        "id": "k4lKWSq_MeXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis\n",
        "Visualize the distribution of image types."
      ],
      "metadata": {
        "id": "j5MPc7-qMf8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "counts = {\n",
        "    'Normal': len(np.where(total_image == 0)[0]),\n",
        "    'Viral Pneumonia': len(np.where(total_image == 1)[0]),\n",
        "    'COVID': len(np.where(total_image == 2)[0])\n",
        "}\n",
        "\n",
        "class_labels = list(counts.keys())\n",
        "class_counts = list(counts.values())\n",
        "\n",
        "plt.bar(class_labels, class_counts)\n",
        "plt.xlabel('Classes')\n",
        "plt.ylabel('Counts')\n",
        "plt.title('Distribution of Image Types')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8_dJTHh0MfoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Display Sample Images\n",
        "Display sample images from each class."
      ],
      "metadata": {
        "id": "Lxplg0kBMluA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def image_plot(generator, images_per_class):\n",
        "    class_indices = generator.class_indices\n",
        "    class_names = list(class_indices.keys())\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    for class_idx, class_name in enumerate(class_names):\n",
        "        class_indices = [i for i, value in enumerate(generator.classes) if value == class_idx]\n",
        "        selected_indices = class_indices[:images_per_class]\n",
        "        for i, idx in enumerate(selected_indices):\n",
        "            ax = plt.subplot(len(class_names), images_per_class, class_idx * images_per_class + i + 1)\n",
        "            img = plt.imread(generator.filepaths[idx])\n",
        "            plt.imshow(img)\n",
        "            plt.title(class_name)\n",
        "            plt.axis(\"off\")\n",
        "\n",
        "images_per_class = 2\n",
        "image_plot(train_data, images_per_class)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "R70vi5wnMp0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Model Building\n",
        "Define the Model\n",
        "Define and compile the model."
      ],
      "metadata": {
        "id": "fc70T4b3MrRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "input_shape = (height, width, 3)\n",
        "base_model = tf.keras.applications.vgg16.VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "base_model.trainable = False\n",
        "\n",
        "ai_model = tf.keras.Sequential()\n",
        "ai_model.add(base_model)\n",
        "ai_model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
        "ai_model.add(tf.keras.layers.Flatten())\n",
        "ai_model.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
        "\n",
        "ai_model.compile(loss='SparseCategoricalCrossentropy', optimizer=tf.keras.optimizers.Adam(0.001), metrics=['acc'])\n",
        "ai_model.summary()\n"
      ],
      "metadata": {
        "id": "zwG4mURlMxab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the Model\n",
        "Train the model using the training data"
      ],
      "metadata": {
        "id": "8-4YTT3zM0VN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('model/ai_model_best.saved', monitor='acc', verbose=1, mode='max', save_best_only=True)\n",
        "early = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", mode=\"min\", restore_best_weights=True, patience=5)\n",
        "callbacks_list = [checkpoint, early]\n",
        "\n",
        "history = ai_model.fit(\n",
        "    train_data,\n",
        "    validation_data=test_data,\n",
        "    epochs=25,\n",
        "    shuffle=False,\n",
        "    verbose=True,\n",
        "    callbacks=callbacks_list\n",
        ")\n"
      ],
      "metadata": {
        "id": "gMaqnOz0M2mM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Model Evaluation\n",
        "Evaluate Model on Training Data\n",
        "Evaluate the model's performance on the training data."
      ],
      "metadata": {
        "id": "vCXe9O1DM745"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ytrain = np.array([])\n",
        "xtrain = []\n",
        "\n",
        "for i in range(math.ceil(len(train_data.classes) / batch_size)):\n",
        "    xtrain.append(train_data[i][0])\n",
        "    ytrain = np.concatenate((ytrain, train_data[i][-1]))\n",
        "\n",
        "xtrain = np.concatenate((xtrain), axis=0)\n",
        "\n",
        "ypred_prob_train = ai_model.predict(xtrain)\n",
        "ypred_train = np.argmax(ypred_prob_train, axis=1)\n",
        "\n",
        "model_train_score = recall_score(ytrain, ypred_train, average='macro')\n",
        "print(\"Model Score on Train Data:\", np.round(100 * model_train_score, 2))\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "hm = sns.heatmap(confusion_matrix(ytrain, ypred_train), annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False, xticklabels=['Normal', 'Viral Pneumonia', 'Covid'], yticklabels=['Normal', 'Viral Pneumonia', 'Covid'])\n",
        "hm.set(xlabel='Predicted labels', ylabel='True label')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "AOhe35YnM9lz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate Model on Testing Data\n",
        "Evaluate the model's performance on the testing data."
      ],
      "metadata": {
        "id": "wwWx75S-NB8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ytest = np.array([])\n",
        "xtest = []\n",
        "\n",
        "for i in range(math.ceil(len(test_data.classes) / batch_size)):\n",
        "    xtest.append(test_data[i][0])\n",
        "    ytest = np.concatenate((ytest, test_data[i][-1]))\n",
        "\n",
        "xtest = np.concatenate((xtest), axis=0)\n",
        "\n",
        "ypred_prob_test = ai_model.predict(xtest)\n",
        "ypred_test = np.argmax(ypred_prob_test, axis=1)\n",
        "\n",
        "model_test_score = recall_score(ytest, ypred_test, average='macro')\n",
        "print(\"Model Score on Test Data:\", np.round(100 * model_test_score, 2))\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "hm = sns.heatmap(confusion_matrix(ytest, ypred_test), annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False, xticklabels=['Normal', 'Viral Pneumonia', 'Covid'], yticklabels=['Normal', 'Viral Pneumonia', 'Covid'])\n",
        "hm.set(xlabel='Predicted labels', ylabel='True label')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Uvxi9xVXNEw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Model Deployment\n",
        "Save the Model\n",
        "Save the trained model to Google Drive."
      ],
      "metadata": {
        "id": "WttyBjrpNIvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "saved_model_path = \"/content/drive/MyDrive/Colab Notebooks/covid_detector.joblib\"\n",
        "joblib.dump(ai_model, saved_model_path)\n"
      ],
      "metadata": {
        "id": "DPlziXX7NVyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the Model\n",
        "Load the saved model for deployment."
      ],
      "metadata": {
        "id": "-Swlu1N5Nc4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "covid_detector = joblib.load(saved_model_path)\n"
      ],
      "metadata": {
        "id": "xpY74KXPNfqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Prediction Function\n",
        "Define a function to make predictions using the deployed model."
      ],
      "metadata": {
        "id": "b7OfzpQzNjXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = gr.Image()\n",
        "label = gr.Label(num_top_classes=3)\n",
        "dimensions = (width, height)\n",
        "class_names = {0: 'Normal', 1: 'Viral Pneumonia', 2: 'Covid'}\n",
        "\n",
        "def predict_covid(image):\n",
        "    image = cv2.resize(image, dimensions, interpolation=cv2.INTER_LINEAR)\n",
        "    image = image / 255.0\n",
        "    image = image.reshape((-1, 224, 224, 3))\n",
        "    prediction = covid_detector.predict(image).flatten()\n",
        "    return {class_names[i]: float(prediction[i]) for i in range(3)}\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=predict_covid,\n",
        "    inputs=image,\n",
        "    outputs=label,\n",
        "    title=\"Detecci√≥n de Covid por X-Ray\",\n",
        "    description=\"Use this to predict whether a given patient is normal, has viral pneumonia, or has COVID based on chest X-ray scan provided.\",\n",
        "    allow_flagging=\"never\"\n",
        ")\n",
        "\n",
        "demo.launch(inline=False, share=True, debug=True)\n"
      ],
      "metadata": {
        "id": "Z1ue6-sBN3s3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Close the Deployed Model\n",
        "Shut down the deployed model."
      ],
      "metadata": {
        "id": "Qxe_bb3VN6xb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "demo.close()\n"
      ],
      "metadata": {
        "id": "w6_gMiLzN9T3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}